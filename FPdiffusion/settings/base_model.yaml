# @package model
_target_: src.models.full_atom.module.FullAtomLitModule

stage: ???

lr_warmup_steps: 5000
val_gen_every_n_epochs: 1000
# Reference the variable defined in train.yaml
output_dir: ${paths.output_dir}
log_loss_name: ["total", "rot", "trans", "bb_coords", "bb_dist_map", "torsion", "fape"]

diffuser:
  _target_: src.models.full_atom.diffuser.se3_diffuser.SE3Diffuser
  se3_conf:
    diffuse_trans: true
    diffuse_rot: true
    r3:
      min_b: 0.1
      max_b: 20.0
      coordinate_scaling: 0.1
    so3:
      num_omega: 1000
      num_sigma: 1000
      min_sigma: 0.1
      max_sigma: 1.5
      schedule: "logarithmic"
      cache_dir: ".cache/"
      use_cached_score: False

score_network:
  _target_: src.models.full_atom.score_network.BaseScoreNetwork
  model_nn:
    _target_: src.models.full_atom.model_nn.base.FoldNet
    embedder:
      _target_: src.models.full_atom.model_nn.embedder.Embedder
      time_emb_size: 64
      scale_t: 1000. 
      res_idx_emb_size: 64
      num_rbf: 64
      rbf_min: 0.
      rbf_max: 5.
      pretrained_node_repr_size: ${data.repr_loader.node_size}
      pretrained_edge_repr_size: ${data.repr_loader.edge_size}
      node_emb_size: 256
      edge_emb_size: 128

    structure_module:
      _target_: src.models.full_atom.model_nn.structure_module.StructureModule
      num_ipa_blocks: 6
      c_s: 256
      c_z: 128
      c_hidden: 256
      c_skip: 64
      no_heads: 6
      no_qk_points: 8
      no_v_points: 12
      seq_tfmr_num_heads: 8
      seq_tfmr_num_layers: 2

  cfg:
    rot_loss_weight: 0.5
    rot_angle_loss_t_filter: 0.2
    trans_loss_weight: 1.0
    bb_coords_loss_weight: 0.2
    bb_coords_loss_t_filter: 0.2
    bb_dist_map_loss_weight: 0.2
    bb_dist_map_loss_t_filter: 0.2
    torsion_loss_weight: 0.5
    fape_loss_weight: 1.0
    num_samples: 2
    scale_coords: 0.1
    diffusion_steps: 100

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 3e-4
  weight_decay: 0.0

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.5
  patience: 10
  threshold: 0.001
  min_lr: 1e-6